import { VoiceRequest, WordAlignment } from '../engines/types';
import { generateSpeech } from '../voice';
import { spawn } from 'child_process';
import path from 'path';
import fs from 'fs/promises';
import os from 'os';

// Helper function to convert ArrayBuffer to Buffer
function arrayBufferToBuffer(arrayBuffer: ArrayBuffer): Buffer {
	return Buffer.from(new Uint8Array(arrayBuffer));
}

// Helper function to get temp directory
function getTmpDir(): string {
	return process.env.VERCEL ? '/tmp' : os.tmpdir();
}

// Helper to resolve Python path, preferring venv but falling back to system python3
async function resolvePythonPath(): Promise<string> {
	if (process.env.PYTHON_PATH) {
		return process.env.PYTHON_PATH;
	}
	const venvPath = path.join(process.cwd(), 'venv', 'bin', 'python3');
	try {
		await fs.access(venvPath);
		return venvPath;
	} catch {
		return 'python3';
	}
}

// Helper: generate TTS with edge-tts (Python). Returns the path written.
async function generateEdgeTTS(text: string, outPath: string): Promise<string> {
	const pythonPath = await resolvePythonPath();
	return new Promise((resolve, reject) => {
		const script = `
import asyncio, edge_tts, sys
text = sys.argv[1]
out = sys.argv[2]
voice = "en-US-GuyNeural"
async def main():
    communicate = edge_tts.Communicate(text, voice)
    await communicate.save(out)
asyncio.run(main())
`;
		const child = spawn(pythonPath, ['-c', script, text, outPath]);
		let stderr = '';
		child.stderr.on('data', d => { stderr += d.toString(); });
		child.on('close', code => {
			if (code === 0) resolve(outPath);
			else reject(new Error(`edge-tts exited ${code}: ${stderr}`));
		});
		child.on('error', err => reject(err));
	});
}

// Helper function to create a silent WAV audio buffer for testing
function createSilentAudioBuffer(durationSeconds: number): Buffer {
	const sampleRate = 22050; // 22.05 kHz
	const channels = 1; // Mono
	const bitsPerSample = 16;
	const bytesPerSample = bitsPerSample / 8;
	const blockAlign = channels * bytesPerSample;
	const byteRate = sampleRate * blockAlign;
	const dataSize = Math.floor(durationSeconds * sampleRate) * blockAlign;
	const fileSize = 36 + dataSize;

	const buffer = Buffer.alloc(44 + dataSize);
	let offset = 0;

	// WAV header
	buffer.write('RIFF', offset); offset += 4;
	buffer.writeUInt32LE(fileSize, offset); offset += 4;
	buffer.write('WAVE', offset); offset += 4;
	
	// Format chunk
	buffer.write('fmt ', offset); offset += 4;
	buffer.writeUInt32LE(16, offset); offset += 4; // Subchunk1Size
	buffer.writeUInt16LE(1, offset); offset += 2; // AudioFormat (PCM)
	buffer.writeUInt16LE(channels, offset); offset += 2;
	buffer.writeUInt32LE(sampleRate, offset); offset += 4;
	buffer.writeUInt32LE(byteRate, offset); offset += 4;
	buffer.writeUInt16LE(blockAlign, offset); offset += 2;
	buffer.writeUInt16LE(bitsPerSample, offset); offset += 2;
	
	// Data chunk
	buffer.write('data', offset); offset += 4;
	buffer.writeUInt32LE(dataSize, offset); offset += 4;
	
	// Fill with silence (zeros)
	buffer.fill(0, offset);
	
	return buffer;
}

export async function generateTTSAndAlignment(
	text: string,
	voice: VoiceRequest,
	jobId: string
): Promise<{ audioPath: string; alignmentPath: string; duration: number }> {
	console.log(`üéôÔ∏è Starting TTS generation for job: ${jobId}`);
	console.log(`üìù Text length: ${text.length} characters`);
	console.log(`üé§ Voice provider: ${voice.provider}, voiceId: ${voice.voiceId}`);
	
	const tmpDir = getTmpDir();
	const jobDir = path.join(tmpDir, 'jobs', jobId);
	
	console.log(`üìÅ Temp dir: ${tmpDir}`);
	console.log(`üìÇ Job dir: ${jobDir}`);
	
	try {
		await fs.mkdir(jobDir, { recursive: true });
		console.log('‚úÖ Job directory created successfully');
	} catch (dirError: any) {
		console.error('‚ùå Failed to create job directory:', dirError);
		throw new Error(`Failed to create job directory: ${dirError.message}`);
	}

	// Use wav for ElevenLabs, mp3 for edge-tts
	let audioPath = path.join(jobDir, 'voice.wav');
	const alignmentPath = path.join(jobDir, 'align.json');

	console.log(`üéµ Audio will be saved to: ${audioPath}`);
	console.log(`üìã Alignment will be saved to: ${alignmentPath}`);

	let alignment: WordAlignment[] = [];
	let duration = 5.0; // Default duration

	// Handle different voice providers
	if (voice.provider === 'elevenlabs') {
		const apiKey = process.env.ELEVENLABS_API_KEY;
		if (!apiKey) {
			console.warn('‚ö†Ô∏è ElevenLabs API key not found, switching to edge-tts');
			voice.provider = 'edge';
		}
	}

	// Generate audio
	try {
		if (voice.provider === 'elevenlabs') {
			console.log('üîÑ Using ElevenLabs API...');
			const audioBuffer = await generateSpeech({
				text,
				voice: { id: voice.voiceId || 'adam', gender: 'male' }
			});
			await fs.writeFile(audioPath, arrayBufferToBuffer(audioBuffer));
			console.log('‚úÖ ElevenLabs audio saved successfully');
		} else if (voice.provider === 'edge') {
			console.log('üîÑ Using edge-tts...');
			// Save as MP3 to avoid re-encoding
			audioPath = path.join(jobDir, 'voice.mp3');
			await generateEdgeTTS(text, audioPath);
			console.log('‚úÖ Edge TTS audio saved successfully');
		} else {
			// Fallback: create silent audio
			console.log('üîÑ Creating fallback silent audio...');
			const estimatedDuration = Math.max(text.length * 0.08, 2); // 0.08s per character, min 2s
			const fallbackAudio = createSilentAudioBuffer(estimatedDuration);
			console.log(`üìä Creating ${estimatedDuration}s of silent audio (${fallbackAudio.length} bytes)`);
			await fs.writeFile(audioPath, fallbackAudio);
			console.log('‚úÖ Fallback silent audio saved successfully');
			duration = estimatedDuration;
		}
		
		// Verify audio file exists
		const audioStats = await fs.stat(audioPath);
		console.log(`‚úÖ Audio file verified: ${audioStats.size} bytes`);
		
	} catch (audioError: any) {
		console.error('‚ùå Audio generation failed:', audioError);
		throw new Error(`Audio generation failed: ${audioError.message}`);
	}

	// Generate word alignment
	try {
		console.log('üîÑ Generating word alignment...');
		alignment = await generateAlignment(audioPath, text);
		console.log(`‚úÖ Generated alignment for ${alignment.length} words`);
	} catch (alignError) {
		console.warn('‚ö†Ô∏è Word alignment failed, using fallback:', alignError);
		alignment = generateFallbackAlignment(text);
		console.log(`‚úÖ Generated fallback alignment for ${alignment.length} words`);
	}

	// Save alignment JSON
	try {
		await fs.writeFile(alignmentPath, JSON.stringify(alignment, null, 2));
		console.log('‚úÖ Alignment data saved successfully');
	} catch (alignSaveError: any) {
		console.error('‚ùå Failed to save alignment:', alignSaveError);
		throw new Error(`Failed to save alignment: ${alignSaveError.message}`);
	}

	// Get actual audio duration if not set
	try {
		duration = await getAudioDuration(audioPath);
		console.log(`‚è±Ô∏è Actual audio duration: ${duration}s`);
	} catch (durationError) {
		console.warn('‚ö†Ô∏è Could not get audio duration, using estimate:', durationError);
		duration = Math.max(text.length * 0.08, 2);
	}

	console.log(`‚úÖ TTS generation completed successfully for job ${jobId}`);
	return {
		audioPath,
		alignmentPath,
		duration
	};
}

async function generateAlignment(audioPath: string, text: string): Promise<WordAlignment[]> {
	try {
		console.log('üîÑ Generating word alignment with Whisper...');
		
		const pythonPath = await resolvePythonPath();

		return new Promise((resolve, reject) => {
			// Create a simple Python script to get word timestamps
			const alignScript = `
import whisper
import sys
import json

try:
    model = whisper.load_model("base")
    result = model.transcribe(sys.argv[1], word_timestamps=True)
    
    words = []
    for segment in result["segments"]:
        if "words" in segment:
            for word in segment["words"]:
                words.append({
                    "word": word["word"].strip(),
                    "start": word["start"],
                    "end": word["end"]
                })
    
    print(json.dumps(words))
except Exception as e:
    print(f"Error: {e}", file=sys.stderr)
    sys.exit(1)
`;

			const pythonProcess = spawn(pythonPath, ['-c', alignScript, audioPath]);
			let stdout = '';
			let stderr = '';

			pythonProcess.stdout.on('data', (data) => {
				stdout += data.toString();
			});

			pythonProcess.stderr.on('data', (data) => {
				stderr += data.toString();
			});

			pythonProcess.on('close', (code) => {
				if (code === 0) {
					try {
						const words = JSON.parse(stdout.trim());
						resolve(words);
					} catch (e) {
						console.error('Failed to parse Whisper output:', e);
						resolve(generateFallbackAlignment(text));
					}
				} else {
					console.error('Whisper failed:', stderr);
					resolve(generateFallbackAlignment(text));
				}
			});

			pythonProcess.on('error', (err) => {
				console.error('Failed to start Whisper process:', err);
				resolve(generateFallbackAlignment(text));
			});
		});
	} catch (error) {
		console.error('Error in generateAlignment:', error);
		return generateFallbackAlignment(text);
	}
}

function generateFallbackAlignment(text: string): WordAlignment[] {
	// Simple fallback: estimate word timing based on average speaking rate
	const words = text.split(/\s+/).filter(word => word.length > 0);
	const avgWordsPerSecond = 2.5; // Reasonable speaking rate
	const wordDuration = 1 / avgWordsPerSecond;
	
	return words.map((word, index) => ({
		word: word.replace(/[.,!?;:]$/, ''), // Remove trailing punctuation
		start: index * wordDuration,
		end: (index + 1) * wordDuration
	}));
}

async function getAudioDuration(audioPath: string): Promise<number> {
	try {
		// First try with ffprobe
		return await getAudioDurationWithFFprobe(audioPath);
	} catch (error) {
		console.warn('ffprobe failed, trying alternative method:', error);
		try {
			// Fallback to librosa via Python
			return await getAudioDurationWithPython(audioPath);
		} catch (pythonError) {
			console.warn('Python duration detection failed:', pythonError);
			// Final fallback - estimate based on file size (very rough)
			return 10; // Default to 10 seconds
		}
	}
}

async function getAudioDurationWithFFprobe(audioPath: string): Promise<number> {
	return new Promise((resolve, reject) => {
		const ffprobe = spawn('ffprobe', [
			'-v', 'quiet',
			'-show_entries', 'format=duration',
			'-of', 'csv=p=0',
			audioPath
		]);

		let stdout = '';
		let stderr = '';

		ffprobe.stdout.on('data', (data) => {
			stdout += data.toString();
		});

		ffprobe.stderr.on('data', (data) => {
			stderr += data.toString();
		});

		ffprobe.on('close', (code) => {
			if (code === 0 && stdout.trim()) {
				const duration = parseFloat(stdout.trim());
				if (duration > 0) {
					resolve(duration);
				} else {
					reject(new Error('Invalid duration from ffprobe'));
				}
			} else {
				reject(new Error(`ffprobe failed with code ${code}: ${stderr}`));
			}
		});

		ffprobe.on('error', (err) => {
			reject(new Error(`Failed to start ffprobe: ${err.message}`));
		});

		// Timeout after 10 seconds
		setTimeout(() => {
			ffprobe.kill();
			reject(new Error('ffprobe timeout'));
		}, 10000);
	});
}

async function getAudioDurationWithPython(audioPath: string): Promise<number> {
	const pythonPath = await resolvePythonPath();

	return new Promise((resolve, reject) => {
		const pythonScript = `
import librosa
import sys
try:
    duration = librosa.get_duration(filename=sys.argv[1])
    print(duration)
except Exception as e:
    print(f"Error: {e}", file=sys.stderr)
    sys.exit(1)
`;

		const pythonProcess = spawn(pythonPath, ['-c', pythonScript, audioPath]);
		let stdout = '';
		let stderr = '';

		pythonProcess.stdout.on('data', (data) => {
			stdout += data.toString();
		});

		pythonProcess.stderr.on('data', (data) => {
			stderr += data.toString();
		});

		pythonProcess.on('close', (code) => {
			if (code === 0 && stdout.trim()) {
				const duration = parseFloat(stdout.trim());
				if (duration > 0) {
					resolve(duration);
				} else {
					reject(new Error('Invalid duration from Python'));
				}
			} else {
				reject(new Error(`Python duration detection failed: ${stderr}`));
			}
		});

		pythonProcess.on('error', (err) => {
			reject(new Error(`Failed to start Python: ${err.message}`));
		});

		// Timeout after 10 seconds
		setTimeout(() => {
			pythonProcess.kill();
			reject(new Error('Python duration detection timeout'));
		}, 10000);
	});
}

export async function generateTitleAndStoryAudio(
	title: string,
	story: string,
	voice: VoiceRequest,
	jobId: string
): Promise<{
	titleAudio: { path: string; alignment: WordAlignment[]; duration: number };
	storyAudio: { path: string; alignment: WordAlignment[]; duration: number };
}> {
	console.log('üéôÔ∏è Generating title and story audio...');

	// Create a shared job directory
	const tmpDir = getTmpDir();
	const jobDir = path.join(tmpDir, 'jobs', jobId);
	await fs.mkdir(jobDir, { recursive: true });

	// Generate title audio
	const titleResult = await generateTTSAndAlignment(title, voice, `${jobId}_title`);
	// Generate story audio
	const storyResult = await generateTTSAndAlignment(story, voice, `${jobId}_story`);

	// Copy files to the main job directory preserving extensions
	const titleExt = path.extname(titleResult.audioPath) || '.wav';
	const storyExt = path.extname(storyResult.audioPath) || '.wav';
	const titleAudioPath = path.join(jobDir, `title_audio${titleExt}`);
	const storyAudioPath = path.join(jobDir, `story_audio${storyExt}`);
	const titleAlignPath = path.join(jobDir, 'title_align.json');
	const storyAlignPath = path.join(jobDir, 'story_align.json');

	await fs.copyFile(titleResult.audioPath, titleAudioPath);
	await fs.copyFile(storyResult.audioPath, storyAudioPath);
	await fs.copyFile(titleResult.alignmentPath, titleAlignPath);
	await fs.copyFile(storyResult.alignmentPath, storyAlignPath);

	// Load alignments
	const titleAlignment: WordAlignment[] = JSON.parse(
		await fs.readFile(titleAlignPath, 'utf-8')
	);
	const storyAlignment: WordAlignment[] = JSON.parse(
		await fs.readFile(storyAlignPath, 'utf-8')
	);

	return {
		titleAudio: {
			path: titleAudioPath,
			alignment: titleAlignment,
			duration: titleResult.duration
		},
		storyAudio: {
			path: storyAudioPath,
			alignment: storyAlignment,
			duration: storyResult.duration
		}
	};
} 